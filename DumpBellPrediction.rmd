---
title: "Acitivty Prediction"
author: "Alex Chang"
date: "Saturday, November 22, 2014"
output: html_document
---

The purpose of this report is to analyize data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to determine the manner of in which they did the excericse.

```{r}
myData <- read.csv("./data/training.csv")

# Loading librarys
library(corrplot);library(caret);library(rpart);
```


# Variable Selection
I start off by looking near zero variance covariates. And select the covariates
that are both not near zero and not NA.  

```{r}
nsv <- nearZeroVar(myData, saveMetrics=TRUE)
# exame the data
nsv
# Remove near zero variances
myData <- myData[,c(nsv$nzv==FALSE)]
# Remove variances that has NA
myData <- myData[,(colSums(is.na(myData))==0)]
# Remove covariaates X as it is completely unique and factor variables except classe (this is the predictor)
myData <- myData[,7:ncol(myData)]
```

This results in `dim(training)[2]` of covariates. 

# Split data into test set and validation set
```{r}
inTrain <- createDataPartition(y=myData$classe,p=0.7,list=FALSE)
training <- myData[inTrain,]; testing <- myData[-inTrain,]
```
This created a training set of `dim(training)` and validation set of `dim(testing)`

# Correlation Analysis
```{r}
M <- abs(cor(training[,-53]))
diag(M) <- 0
cor <- which(M > 0.9, arr.ind=T)
```

Based on the correlation analysis, it reveals that there are `nrow(cor)` variables that are highly correlated to each other.  Therefore, I will use Principal Components Analysis (PCA) as preprocessing step in the model fitting

# Training control
To cross validate, I used the k-fold cross validation with 3 repeat repetitions.
```{r}
ctrl <- trainControl(method = "repeatedcv", repeats = 5)
```

# Model Fitting using Tree
```{r}
modFitTree <- train(classe~.,method="rpart",preProcess="pca",data=training, trControl=ctrl)
plot (modFitTree$finalModel , uniform=TRUE , main="Classification Tree")
text(modFitTree$finalModel, use.n=TRUE, all=TRUE, cex=.8)
modFitTree
```
The first learning algorithm that I choose to use is tree.


# Predict the result using validation set
The validation against the testing set is shown below.
```{r}
predictions <- predict(modFitTree,testing)
confusionMatrix(predictions, testing$classe)
```

# Conclusion
Based on the figure above, model has accuracy of roughly 40%. Therefore, I expect the error rate to be 60%.
